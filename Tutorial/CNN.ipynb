{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn3LRST/MV/u+BBJ02lFcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poppvk935/Astrophysics-Deep-Learning/blob/main/Tutorial/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "AtwRFCLGuGTk"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "tB0zSglRuHBE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform the data\n",
        "#mnist images are 2d but we need a 4d tensor, (number of images, height, width, color channel)\n",
        "#Convern MNIST image files into tensor of 4 Dimensions\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "sdW-d7-vuJ--"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data\n",
        "\n",
        "train_data = datasets.MNIST(root = '/cnn_data', train = True, download = True, transform = transform)"
      ],
      "metadata": {
        "id": "atV06c7nulQ2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data\n",
        "test_data = datasets.MNIST(root = '/cnn_data', train = False, download = True, transform = transform)"
      ],
      "metadata": {
        "id": "w1Kw0Y5ovFHF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojKswpwzvOdZ",
        "outputId": "01e6c5af-a642-497e-ae9a-a8eaacae4e36"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XuCtWqlvRac",
        "outputId": "f373b59f-eb16-4afb-8dd8-3a51feee1f9d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a loader for the data\n",
        "  #need to create batch size, small size\n",
        "train_loader = DataLoader(train_data, batch_size = 10, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 10, shuffle = False)\n"
      ],
      "metadata": {
        "id": "x5l76r8fvuPw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define CNN Model\n",
        "#Describe convolutional layer and what its doing (2 conv layers)\n",
        "#just an example\n",
        "\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1) #6 inputs go with 6 outputs\n"
      ],
      "metadata": {
        "id": "qtoTJTCjwQ_c"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grab 1 MNIST Record/image\n",
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "  break;"
      ],
      "metadata": {
        "id": "GyKKuC6TxODX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7F8AZ_KxWvq",
        "outputId": "349008e6-2d55-4abf-9973-32e4aaf4608a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change to 4d batch\n",
        "x = X_train.view(1,1,28,28 ) #1 batch of 1 image of 28heightx28width"
      ],
      "metadata": {
        "id": "yKXHcn1lxY6t"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform first convolution\n",
        "x = F.relu(conv1(x)) #relu is activation function\n"
      ],
      "metadata": {
        "id": "CeA91woVxoNa"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1 single image, 6 filters/feature maps, 26x26 because we didn't set padding\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj06WnDtx0Ov",
        "outputId": "cfad7cc6-338d-421c-cfd7-37ae99f75517"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pass through pooling layer\n",
        "x = F.max_pool2d(x, 2,2) #kernel size 2, stride size 2"
      ],
      "metadata": {
        "id": "ssEW8fnsx24R"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26/2 = 13\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZngAXZbyn6M",
        "outputId": "17808489-3b30-4c8a-92f3-9c9d8bf2df67"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Do second conv layer\n",
        "\n",
        "x = F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "HvCFbfhdyvcy"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEfebIshzG-P",
        "outputId": "8a0fb6bd-4882-401a-fa0b-3f04e5adaf67"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pooling layer again\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2)"
      ],
      "metadata": {
        "id": "OTYoprnqzH1j"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y91oq9kEzmqH",
        "outputId": "0d3bfe67-33c3-40c1-b5fc-65d2d9730c0a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model class\n",
        "class ConvNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "    #fully connected layers\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "  def forward(self,X):\n",
        "    #First pass\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X, 2,2)\n",
        "    # Second pass\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X, 2,2)\n",
        "    #Re-view to flatten it out\n",
        "    X = X.view(-1, 16*5*5) #negative so we can vary the batch size\n",
        "\n",
        "    #Fully connected layers\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X =(self.fc3(X))\n",
        "\n",
        "    return F.log_softmax(X, dim = 1)"
      ],
      "metadata": {
        "id": "-4-8K5j0zqq2"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an instance of the Model and set manual seed\n",
        "\n",
        "torch.manual_seed(41)\n",
        "model = ConvNN()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1ojlHqU2b-t",
        "outputId": "efc8f363-cb43-4914-e79a-89e591aa6a84"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNN(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss Function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #the smaller the learning rate, the longer it takes to train\n"
      ],
      "metadata": {
        "id": "3CHSbopC2nrl"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "#create variable to track things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "\n",
        "#Foor loop of epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "\n",
        "#train\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    b+=1 #start batches as 1\n",
        "    y_pred = model(X_train) #get predicted values from training set\n",
        "    loss = criterion(y_pred, y_train) #how off are we\n",
        "\n",
        "\n",
        "    predicted = torch.max(y_pred.data, 1)[1] #add up number of correct predictions, indexed off of first point\n",
        "    batch_correct = (predicted == y_train).sum() #how many we got correct from specific batch, true = 1, false = 0\n",
        "    trn_corr +=batch_correct #keep track as we go along and train\n",
        "\n",
        "  #update parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  #print results\n",
        "    if(b%600 == 0):\n",
        "      print(f'Epoch: {i} Batch: {b} Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "#test\n",
        "\n",
        "with torch.no_grad(): # no gradient so we dont update weights and biases\n",
        "  for b,(X_test, y_test) in enumerate(test_loader):\n",
        "    y_val = model(X_test)\n",
        "    predicted = torch.max(y_val.data, 1)[1]\n",
        "    tst_corr += (predicted == y_test).sum()\n",
        "loss = criterion(y_val, y_test)\n",
        "test_losses.append(loss)\n",
        "test_correct.append(tst_corr)\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "\n",
        "total = current_time - start_time\n",
        "print(f'Training took: {total/60} minutes')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PMXmJVM3Cng",
        "outputId": "f4ce65c4-b283-4a00-ff40-437ab863e690"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Batch: 600 Loss: 0.1623610556125641\n",
            "Epoch: 0 Batch: 1200 Loss: 0.1502392590045929\n",
            "Epoch: 0 Batch: 1800 Loss: 0.4744560718536377\n",
            "Epoch: 0 Batch: 2400 Loss: 0.14238706231117249\n",
            "Epoch: 0 Batch: 3000 Loss: 0.007758188061416149\n",
            "Epoch: 0 Batch: 3600 Loss: 0.3836284875869751\n",
            "Epoch: 0 Batch: 4200 Loss: 0.0038223876617848873\n",
            "Epoch: 0 Batch: 4800 Loss: 0.0021286322735249996\n",
            "Epoch: 0 Batch: 5400 Loss: 0.0569545142352581\n",
            "Epoch: 0 Batch: 6000 Loss: 0.00038789428072050214\n",
            "Epoch: 1 Batch: 600 Loss: 0.06289136409759521\n",
            "Epoch: 1 Batch: 1200 Loss: 0.010614877566695213\n",
            "Epoch: 1 Batch: 1800 Loss: 0.03243611007928848\n",
            "Epoch: 1 Batch: 2400 Loss: 0.012448625639081001\n",
            "Epoch: 1 Batch: 3000 Loss: 0.000640809943433851\n",
            "Epoch: 1 Batch: 3600 Loss: 0.0020938280504196882\n",
            "Epoch: 1 Batch: 4200 Loss: 0.3140248656272888\n",
            "Epoch: 1 Batch: 4800 Loss: 0.020231451839208603\n",
            "Epoch: 1 Batch: 5400 Loss: 0.0031914091669023037\n",
            "Epoch: 1 Batch: 6000 Loss: 0.0009488927898928523\n",
            "Epoch: 2 Batch: 600 Loss: 0.04242878407239914\n",
            "Epoch: 2 Batch: 1200 Loss: 0.000786997377872467\n",
            "Epoch: 2 Batch: 1800 Loss: 0.0004456916940398514\n",
            "Epoch: 2 Batch: 2400 Loss: 0.0021735907066613436\n",
            "Epoch: 2 Batch: 3000 Loss: 6.313459743978456e-05\n",
            "Epoch: 2 Batch: 3600 Loss: 0.0014708992093801498\n",
            "Epoch: 2 Batch: 4200 Loss: 8.743518264964223e-05\n",
            "Epoch: 2 Batch: 4800 Loss: 0.0011174092069268227\n",
            "Epoch: 2 Batch: 5400 Loss: 0.00019280910782981664\n",
            "Epoch: 2 Batch: 6000 Loss: 0.00013335500261746347\n",
            "Epoch: 3 Batch: 600 Loss: 0.20401248335838318\n",
            "Epoch: 3 Batch: 1200 Loss: 0.0011065044673159719\n",
            "Epoch: 3 Batch: 1800 Loss: 0.00048520020209252834\n",
            "Epoch: 3 Batch: 2400 Loss: 0.0013440614566206932\n",
            "Epoch: 3 Batch: 3000 Loss: 0.00839989073574543\n",
            "Epoch: 3 Batch: 3600 Loss: 9.791700722416863e-05\n",
            "Epoch: 3 Batch: 4200 Loss: 0.0046706534922122955\n",
            "Epoch: 3 Batch: 4800 Loss: 0.002486269222572446\n",
            "Epoch: 3 Batch: 5400 Loss: 0.03304066136479378\n",
            "Epoch: 3 Batch: 6000 Loss: 0.0277620367705822\n",
            "Epoch: 4 Batch: 600 Loss: 0.04214929789304733\n",
            "Epoch: 4 Batch: 1200 Loss: 0.0015658453339710832\n",
            "Epoch: 4 Batch: 1800 Loss: 4.677330798585899e-05\n",
            "Epoch: 4 Batch: 2400 Loss: 0.00042244786163792014\n",
            "Epoch: 4 Batch: 3000 Loss: 0.554036021232605\n",
            "Epoch: 4 Batch: 3600 Loss: 0.00038964804843999445\n",
            "Epoch: 4 Batch: 4200 Loss: 0.027548160403966904\n",
            "Epoch: 4 Batch: 4800 Loss: 0.004602053668349981\n",
            "Epoch: 4 Batch: 5400 Loss: 0.05360576510429382\n",
            "Epoch: 4 Batch: 6000 Loss: 0.03545317426323891\n",
            "Training took: 3.1069145798683167 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQuZ5hrn6fJG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}